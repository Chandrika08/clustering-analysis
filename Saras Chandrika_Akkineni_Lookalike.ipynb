{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: Lookalike Model"
      ],
      "metadata": {
        "id": "e86KValg2Pel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lookalike Model Approach\n",
        "1. Data Used:\n",
        "* Merged Customers.csv (customer profiles) and Transactions.csv (transaction history) to create a unified dataset with both customer data and transaction details.\n",
        "2. Similarity Calculation:\n",
        "* Used features like Total Purchase Value, Average Order Value, Total Quantity, and Region (encoded) to calculate customer similarity using Cosine Similarity.\n",
        "3. Selecting Top 3 Lookalikes:\n",
        "* For each customer, the top 3 most similar customers were selected by sorting the cosine similarity scores in descending order, excluding the customer itself.\n",
        "4. Final Output:\n",
        "* Saved the lookalike recommendations for the first 20 customers in a CSV file, including CustomerID, Lookalikes (3 similar customers), and Scores (similarity scores).\n",
        "5. Mean Pairwise Distance:\n",
        "* Calculated the mean pairwise distance between the train and test data to assess model accuracy. Lower distance means better customer similarity grouping.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1mvKeIXw0ZYI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logic Used:\n",
        "1. Feature Engineering:\n",
        "\n",
        "* Aggregated transaction data (e.g., total purchase value, quantity) and encoded categorical features (e.g., region) to create a customer feature set.\n",
        "2. Dimensionality Reduction:\n",
        "\n",
        "* Applied PCA to reduce the dimensionality of customer features, retaining the most important patterns while reducing noise.\n",
        "3. Similarity Measurement:\n",
        "\n",
        "* Used Cosine Similarity to compare customers based on their reduced feature vectors, where higher similarity indicates more similar customers."
      ],
      "metadata": {
        "id": "P8gq54XtC5bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import pairwise_distances\n",
        "\n",
        "# Step 1: Load the data\n",
        "customers_df = pd.read_csv('/content/Customers.csv')\n",
        "transactions_df = pd.read_csv('/content/Transactions.csv')\n",
        "products_df = pd.read_csv('/content/Products.csv')\n",
        "\n",
        "# Step 2: Merge and aggregate data\n",
        "merged_transactions = transactions_df.merge(products_df, on=\"ProductID\", how=\"left\")\n",
        "\n",
        "# Clean column names by stripping any leading/trailing spaces\n",
        "merged_transactions.columns = merged_transactions.columns.str.strip()\n",
        "\n",
        "customer_transactions = merged_transactions.merge(customers_df, on=\"CustomerID\", how=\"left\")\n",
        "\n",
        "# Inspect the merged DataFrame to ensure 'Price' column exists\n",
        "print(customer_transactions.head())  # This is for debugging, remove it after confirming\n",
        "\n",
        "# Aggregate transaction-level data into customer-level features\n",
        "customer_features = customer_transactions.groupby(\"CustomerID\").agg({\n",
        "    \"TotalValue\": \"sum\",\n",
        "    \"Quantity\": \"sum\",\n",
        "    \"Price_x\": \"mean\",  # Make sure the 'Price' column exists\n",
        "    \"Category\": lambda x: x.mode()[0] if not x.mode().empty else None\n",
        "}).reset_index()\n",
        "\n",
        "customer_features.columns = [\"CustomerID\", \"TotalPurchaseValue\", \"TotalQuantity\", \"AvgPrice\", \"TopCategory\"]\n",
        "customer_features = customer_features.merge(customers_df, on=\"CustomerID\", how=\"left\")\n",
        "\n",
        "# Step 3: Encode categorical features\n",
        "encoder = OneHotEncoder()\n",
        "encoded_category = pd.DataFrame(encoder.fit_transform(customer_features[[\"TopCategory\"]]).toarray(),\n",
        "                                columns=encoder.get_feature_names_out([\"TopCategory\"]))\n",
        "encoded_region = pd.get_dummies(customer_features[\"Region\"], prefix=\"Region\")\n",
        "\n",
        "# Combine features into a single DataFrame\n",
        "customer_features = pd.concat([customer_features, encoded_category, encoded_region], axis=1)\n",
        "customer_features.drop(columns=[\"Region\", \"CustomerName\", \"SignupDate\", \"TopCategory\"], inplace=True)\n",
        "\n",
        "# Step 4: Standardize numerical features\n",
        "scaler = StandardScaler()\n",
        "numerical_features = [\"TotalPurchaseValue\", \"TotalQuantity\", \"AvgPrice\"]\n",
        "customer_features[numerical_features] = scaler.fit_transform(customer_features[numerical_features])\n",
        "\n",
        "# Step 5: Dimensionality reduction with PCA\n",
        "pca = PCA(n_components=5)\n",
        "customer_pca = pca.fit_transform(customer_features.drop(columns=[\"CustomerID\"]).set_index(customer_features[\"CustomerID\"]))\n",
        "customer_features_pca = pd.DataFrame(customer_pca, index=customer_features[\"CustomerID\"])\n",
        "\n",
        "# Step 6: Calculate similarity\n",
        "similarity_matrix = cosine_similarity(customer_features_pca)\n",
        "similarity_df = pd.DataFrame(similarity_matrix, index=customer_features[\"CustomerID\"], columns=customer_features[\"CustomerID\"])\n",
        "\n",
        "# Step 7: Recommend lookalikes\n",
        "lookalike_results = {}\n",
        "for customer_id in customer_features[\"CustomerID\"][:20]:\n",
        "    similar_customers = similarity_df[customer_id].sort_values(ascending=False).iloc[1:4]\n",
        "    lookalike_results[customer_id] = list(similar_customers.index), list(similar_customers.values)\n",
        "\n",
        "# Convert to DataFrame\n",
        "lookalike_df = pd.DataFrame([{\n",
        "    \"CustomerID\": cust_id,\n",
        "    \"Lookalikes\": lookalike_results[cust_id][0],\n",
        "    \"Scores\": lookalike_results[cust_id][1]\n",
        "} for cust_id in lookalike_results])\n",
        "\n",
        "# Step 8: Print sample rows for clarity\n",
        "print(lookalike_df.head())\n",
        "\n",
        "# Step 9: Save results\n",
        "lookalike_df.to_csv(\"Saras Chandrika_Akkineni_Lookalike.csv\", index=False)\n",
        "\n",
        "# Step 10: Accuracy estimation\n",
        "# Splitting data for evaluation (train-test split for synthetic validation)\n",
        "train, test = train_test_split(customer_features_pca, test_size=0.2, random_state=42)\n",
        "train_similarity = cosine_similarity(train)\n",
        "test_similarity = cosine_similarity(test, train)\n",
        "\n",
        "# Evaluate the quality of similarity (lower distance = better similarity match)\n",
        "mean_distance = pairwise_distances(test, train).mean()\n",
        "print(f\"Mean pairwise distance between test and train data: {mean_distance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqWBu39l9dSI",
        "outputId": "23d64773-5db0-49df-88a4-8255459a6e51"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
            "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
            "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
            "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
            "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
            "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
            "\n",
            "   TotalValue  Price_x                      ProductName     Category  Price_y  \\\n",
            "0      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "1      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "2      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "3      601.36   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "4      902.04   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
            "\n",
            "      CustomerName         Region  SignupDate  \n",
            "0   Andrea Jenkins         Europe  2022-12-03  \n",
            "1  Brittany Harvey           Asia  2024-09-04  \n",
            "2  Kathryn Stevens         Europe  2024-04-04  \n",
            "3  Travis Campbell  South America  2024-04-11  \n",
            "4    Timothy Perez         Europe  2022-03-15  \n",
            "  CustomerID             Lookalikes  \\\n",
            "0      C0001  [C0181, C0120, C0184]   \n",
            "1      C0002  [C0088, C0029, C0144]   \n",
            "2      C0003  [C0190, C0091, C0025]   \n",
            "3      C0004  [C0165, C0153, C0087]   \n",
            "4      C0005  [C0140, C0186, C0020]   \n",
            "\n",
            "                                              Scores  \n",
            "0  [0.9182085994673006, 0.8588007203470517, 0.818...  \n",
            "1  [0.9846740947527882, 0.9790873581204309, 0.975...  \n",
            "2  [0.8751495545188616, 0.8694794962149012, 0.837...  \n",
            "3  [0.9808092462395755, 0.9214454554317103, 0.920...  \n",
            "4  [0.9952752068115471, 0.9819186844992734, 0.962...  \n",
            "Mean pairwise distance between test and train data: 2.4995\n"
          ]
        }
      ]
    }
  ]
}